seed: 42
work_dir: ./work_dir_DIV2K
expr: 'DIV2K'
wandb_project: 
wandb_entity: yuanzhi_zhu
wandb_key: ''
use_tensorboard: True

# Dataset parameters
dataset:
  img_size: 256
  batch_size: 32
  train_path: [./DIV2K_train_HR]
  val_path: [./DIV2K_valid_HR]
  num_workers: 16
  resize_size: 0
  random_crop: True
  center_crop: False
  val_img_size: 512
  random_crop_val: False
  center_crop_val: True
  use_aug: False
  num_classes: 

# Image restoration parameters
ir:
  degradation: sr_interp  # [realsr, sr_interp, sr_avp]
  mode: bicubic
  scale_factor: 4
  sigma_y: 0.              # noise in the measurement
  calc_LPIPS: True
  sigma_pertubation: 0.2    # pertubation on the x0 distribution

# Flow matching models parameters
fm_model:
  flow_t_schedule: uniform
  use_cond: True # concate with LR input
  T: 1.
  eps: !!float 0.001

# Unet parameters
network:
  zero_init: True
  model_path: ''
  model_arch: guided_unet   # [CUSRNet, diffuser, IRSDE, SongUNet, guided_unet]
  in_channels: 3
  out_channels: 3
  num_channels: 128
  num_res_blocks: 1
  attention_resolutions: "16"
  num_heads: 4
  dropout: 0.1
  channel_mult: "1, 1, 2, 2, 4, 4"
  resblock_updown: True
  use_group_norm: True
  use_attention: True
  use_input_skip: False
  ema_rate: 0.9999
  skip_mode: concat
  # SwinIR
  depth_per_layer: 4
  patch_size: 1
  window_size: 8

# Training parameters
train:
  resume_from: ''
  pre_train_model: ''
  accumulation_steps: 1
  progress: False
  max_steps: 400000
  loss_type: l1
  weight_schedule: uniform
  record_iters: 100
  validate_iters: 500
  snapshot_freq_for_preemption: 2000
  snapshot_freq: 10000
  use_amp: True
  amp_dtype: fp32
  compile: False  # compile model will lead to strange artifacts in the restored images
  reduce_mean: True

# optimizer parameters
optim:
  optimizer: Adam
  beta1: 0.9
  beta2: 0.999
  eps: !!float 1e-8
  weight_decay: !!float 0.0
  grad_clip: 1.
  lr: !!float 1e-5
  warmup: 500
  lr_decay: 0

# Sampling parameters
sample:
  pre_train_model: ''
  use_ode_sampler: rk45
  sample_N: 8
  ode_tol: !!float 1e-3
  num_sample: 16
  eta: 0.0
  num_psnr_sample: 100
  psnr_batch_size: 16
  noise_var: 0.0
  rho: 1.
  rk2_r: 1.
  file_ext: png

degradation:
  # sf: ${ir.scale_factor}
  # the first degradation process
  resize_prob: [0.2, 0.7, 0.1]  # up, down, keep
  resize_range: [0.15, 1.5]
  gaussian_noise_prob: 0.5
  noise_range: [1, 30]
  poisson_scale_range: [0.05, 3.0]
  gray_noise_prob: 0.4
  jpeg_range: [30, 95]

  # the second degradation process
  second_order_prob: 0.5
  second_blur_prob: 0.8
  resize_prob2: [0.3, 0.4, 0.3]  # up, down, keep
  resize_range2: [0.3, 1.2]
  gaussian_noise_prob2: 0.5
  noise_range2: [1, 25]
  poisson_scale_range2: [0.05, 2.5]
  gray_noise_prob2: 0.4
  jpeg_range2: [30, 95]

  gt_size: 256 
  resize_back: False
  use_sharp: False

data:
  train:
    type: realesrgan
    params:
      # dir_paths: {{ dataset.train_path }}
      txt_file_path: [] 
      im_exts: ['JPEG', 'jpeg', 'jpg', 'png']
      io_backend:
        type: disk
      blur_kernel_size: 21
      kernel_list: ['iso', 'aniso', 'generalized_iso', 'generalized_aniso', 'plateau_iso', 'plateau_aniso']
      kernel_prob: [0.45, 0.25, 0.12, 0.03, 0.12, 0.03]
      sinc_prob: 0.1
      blur_sigma: [0.2, 3.0]
      betag_range: [0.5, 4.0]
      betap_range: [1, 2.0]

      blur_kernel_size2: 15
      kernel_list2: ['iso', 'aniso', 'generalized_iso', 'generalized_aniso', 'plateau_iso', 'plateau_aniso']
      kernel_prob2: [0.45, 0.25, 0.12, 0.03, 0.12, 0.03]
      sinc_prob2: 0.1
      blur_sigma2: [0.2, 1.5]
      betag_range2: [0.5, 4.0]
      betap_range2: [1, 2.0]

      final_sinc_prob: 0.8

      gt_size: 256 # ${degradation.gt_size}
      crop_pad_size: 300
      use_hflip: True
      use_rot: False
      rescale_gt: True
  val:
    type: realesrgan
